# pytorch

## building modules

```python
from torch import nn

def NNModule(nn.Module):
    def __init__(self):
        super(NNModule, self).__init__()
        # define module here

    # define forward pass here
    def forward(self, x):
        return output
```

## training loop

```python
from torch import nn
import torch.optim as optim

from tqdm import tqdm

# define model
model = define_model()
# define optimizer parameters
opt_params = {}

# define loss function
# loss function should take
#   in: (model_output, expected_model_output)
#   out: a single value (the loss)
loss_fn = define_loss_function()

# create optimizier
opt = optim.Optimizer(model.parameters(), **opt_params)

# create dataloader
# should be an iterator that returns (X, y)
dataloader = define_dataloader()

# train loop
num_epochs = 30

for epoch in range(1, num_epochs + 1):

    for batch, (X, y) in enumerate(tqdm(dataloader)):
        # compute forward pass and loss
        pred = model(*inputs)
        loss = loss_fn(pred, y)

        # backpropagation
        opt.zero_grad()
        loss.backward()
        opt.step()
```

## [commonly used optimizers (and notes)](https://pytorch.org/docs/stable/optim.html)

### SGD

### RMSprop

### Adagrad